op0: SchedulerNode(ComputedBuffer)
op0.writes = [MemoryDep('buf0', c0, {c0: 2000}, None)]
op0.unmet_dependencies = []
op0.met_dependencies = 
    [   MemoryDep('addmm', c0, {c0: 2000}, None),
        MemoryDep('tangents_1', c0, {c0: 2000}, None)]
op0.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
    buf0.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op1'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op2'), can_inplace=False, is_weak=False),
    ]
]
op0.group.device = cuda:0
op0.group.iteration = (2000, 1)
op0.sizes = ([2000], [])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
addmm_layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
class op0_loop_body:
    var_ranges = {z0: 2000}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('tangents_1', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('addmm', get_index_1)
        sin = ops.sin(load_1)
        neg = ops.neg(sin)
        mul = ops.mul(load, neg)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf0', get_index_2, mul, None)
        return store
op0 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties
    triton_helpers.set_driver_to_gpu()

    @triton_heuristics.pointwise(
        size_hints=[2048], 
        filename=__file__,
        triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'CC5CD2B4144D54CA80B78EEF6F54FBFC888FC6846BD6BCF5764202597E9C3FA5', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 2000
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr1 + (x0), xmask)
        tmp2 = tl_math.sin(tmp1)
        tmp3 = -tmp2
        tmp4 = tmp0 * tmp3
        tl.store(out_ptr0 + (x0), tmp4, xmask)


op1: ExternKernelSchedulerNode(ExternKernelOut)
op1.writes = [StarDep(name='buf1', mode=None)]
op1.unmet_dependencies = [StarDep(name='buf0', mode=None)]
op1.met_dependencies = [StarDep(name='primals_3', mode=None)]
op1.outputs = [
    buf1: ExternKernelOut
    buf1.layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
    buf1.users = [NodeUser(node=SchedulerNode(name='op7'), can_inplace=True, is_weak=False)]
]
op1.node.kernel = extern_kernels.mm


op2: SchedulerNode(ComputedBuffer)
op2.writes = [MemoryDep('buf2', 0, {}, None)]
op2.unmet_dependencies = [MemoryDep('buf0', c0, {c0: 2000}, None)]
op2.met_dependencies = []
op2.outputs = [
    buf2: ComputedBuffer
    buf2.layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
    buf2.users = [NodeUser(node=SchedulerNode(name='op6'), can_inplace=True, is_weak=False)]
]
op2.group.device = cuda:0
op2.group.iteration = (1, 2000)
op2.sizes = ([], [2000])
buf0_layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
buf2_layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
class op2_loop_body:
    var_ranges = {z0: 2000}
    index0 = z0
    index1 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf0', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf2', get_index_1, reduction)
        return store_reduction
op2 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties
    triton_helpers.set_driver_to_gpu()

    @triton_heuristics.reduction(
        size_hints=[1, 2048],
        reduction_hint=ReductionHint.INNER,
        filename=__file__,
        triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 3), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'CC5CD2B4144D54CA80B78EEF6F54FBFC888FC6846BD6BCF5764202597E9C3FA5', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 1
        rnumel = 2000
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
        rbase = tl.arange(0, RBLOCK)[None, :]
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r0 = rindex
            tmp0 = tl.load(in_ptr0 + (r0), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp2, None)


op3: SchedulerNode(ComputedBuffer)
op3.writes = [MemoryDep('buf3', c0, {c0: 2000}, None)]
op3.unmet_dependencies = []
op3.met_dependencies = 
    [   MemoryDep('addmm', c0, {c0: 2000}, None),
        MemoryDep('tangents_1', c0, {c0: 2000}, None)]
op3.outputs = [
    buf3: ComputedBuffer
    buf3.layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
    buf3.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op4'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op5'), can_inplace=False, is_weak=False),
    ]
]
op3.group.device = cuda:0
op3.group.iteration = (2000, 1)
op3.sizes = ([2000], [])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
addmm_layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
buf3_layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
class op3_loop_body:
    var_ranges = {z0: 2000}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('tangents_1', get_index)
        constant = ops.constant(2.0, torch.float32)
        mul = ops.mul(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('addmm', get_index_1)
        cos = ops.cos(load_1)
        mul_1 = ops.mul(mul, cos)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf3', get_index_2, mul_1, None)
        return store
op3 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties
    triton_helpers.set_driver_to_gpu()

    @triton_heuristics.pointwise(
        size_hints=[2048], 
        filename=__file__,
        triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'CC5CD2B4144D54CA80B78EEF6F54FBFC888FC6846BD6BCF5764202597E9C3FA5', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 2000
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp3 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = 2.0
        tmp2 = tmp0 * tmp1
        tmp4 = tl_math.cos(tmp3)
        tmp5 = tmp2 * tmp4
        tl.store(out_ptr0 + (x0), tmp5, xmask)


op4: ExternKernelSchedulerNode(ExternKernelOut)
op4.writes = [StarDep(name='buf4', mode=None)]
op4.unmet_dependencies = [StarDep(name='buf3', mode=None)]
op4.met_dependencies = [StarDep(name='primals_3', mode=None)]
op4.outputs = [
    buf4: ExternKernelOut
    buf4.layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
    buf4.users = [NodeUser(node=SchedulerNode(name='op7'), can_inplace=True, is_weak=False)]
]
op4.node.kernel = extern_kernels.mm


op5: SchedulerNode(ComputedBuffer)
op5.writes = [MemoryDep('buf5', 0, {}, None)]
op5.unmet_dependencies = [MemoryDep('buf3', c0, {c0: 2000}, None)]
op5.met_dependencies = []
op5.outputs = [
    buf5: ComputedBuffer
    buf5.layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
    buf5.users = [NodeUser(node=SchedulerNode(name='op6'), can_inplace=True, is_weak=False)]
]
op5.group.device = cuda:0
op5.group.iteration = (1, 2000)
op5.sizes = ([], [2000])
buf3_layout = FixedLayout('cuda', torch.float32, size=[2000, 1], stride=[1, 1])
buf5_layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
class op5_loop_body:
    var_ranges = {z0: 2000}
    index0 = z0
    index1 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf3', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf5', get_index_1, reduction)
        return store_reduction
op5 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties
    triton_helpers.set_driver_to_gpu()

    @triton_heuristics.reduction(
        size_hints=[1, 2048],
        reduction_hint=ReductionHint.INNER,
        filename=__file__,
        triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 3), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'CC5CD2B4144D54CA80B78EEF6F54FBFC888FC6846BD6BCF5764202597E9C3FA5', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 1
        rnumel = 2000
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
        rbase = tl.arange(0, RBLOCK)[None, :]
        _tmp2 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r0 = rindex
            tmp0 = tl.load(in_ptr0 + (r0), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
            tmp3 = _tmp2 + tmp1
            _tmp2 = tl.where(rmask, tmp3, _tmp2)
        tmp2 = tl.sum(_tmp2, 1)[:, None]
        tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp2, None)


op6: SchedulerNode(ComputedBuffer)
op6.writes = [MemoryDep('buf6', 0, {}, None)]
op6.unmet_dependencies = [MemoryDep('buf2', 0, {}, None), MemoryDep('buf5', 0, {}, None)]
op6.met_dependencies = []
op6.outputs = [
    buf6: ComputedBuffer
    buf6.layout = FixedLayout('cuda', torch.float32, size=[1], stride=[1])
    buf6.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op6.group.device = cuda:0
op6.group.iteration = (1, 1)
op6.sizes = ([], [])
buf2_layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
buf5_layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
buf6_layout = FixedLayout('cuda', torch.float32, size=[1], stride=[1])
class op6_loop_body:
    var_ranges = {}
    index0 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf2', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf5', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf6', get_index_2, add, None)
        return store
op6 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties
    triton_helpers.set_driver_to_gpu()

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'CC5CD2B4144D54CA80B78EEF6F54FBFC888FC6846BD6BCF5764202597E9C3FA5', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp0 = tl.load(in_out_ptr0 + (0))
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
        tmp2 = tl.load(in_ptr0 + (0))
        tmp3 = tl.broadcast_to(tmp2, [XBLOCK])
        tmp4 = tmp1 + tmp3
        tl.store(in_out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp4, None)


op7: SchedulerNode(ComputedBuffer)
op7.writes = [MemoryDep('buf7', 0, {}, None)]
op7.unmet_dependencies = [MemoryDep('buf1', 0, {}, None), MemoryDep('buf4', 0, {}, None)]
op7.met_dependencies = []
op7.outputs = [
    buf7: ComputedBuffer
    buf7.layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
    buf7.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op7.group.device = cuda:0
op7.group.iteration = (1, 1)
op7.sizes = ([], [])
buf1_layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
buf7_layout = FixedLayout('cuda', torch.float32, size=[1, 1], stride=[1, 1])
class op7_loop_body:
    var_ranges = {}
    index0 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf4', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf7', get_index_2, add, None)
        return store
op7 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties
    triton_helpers.set_driver_to_gpu()

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'CC5CD2B4144D54CA80B78EEF6F54FBFC888FC6846BD6BCF5764202597E9C3FA5', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp0 = tl.load(in_out_ptr0 + (0))
        tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
        tmp2 = tl.load(in_ptr0 + (0))
        tmp3 = tl.broadcast_to(tmp2, [XBLOCK])
        tmp4 = tmp1 + tmp3
        tl.store(in_out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp4, None)


